{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b47f827",
   "metadata": {},
   "source": [
    "For Single Word File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd82f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import html\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------- Helpers -------------------\n",
    "def is_list_item(paragraph):\n",
    "    return paragraph._element.pPr is not None and paragraph._element.pPr.numPr is not None\n",
    "\n",
    "def convert_run_to_html(run):\n",
    "    text = html.escape(run.text)\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    if run.bold:\n",
    "        text = f\"<strong>{text}</strong>\"\n",
    "    if run.italic:\n",
    "        text = f\"<em>{text}</em>\"\n",
    "    if run.underline:\n",
    "        text = f\"<u>{text}</u>\"\n",
    "    return text\n",
    "\n",
    "def paragraph_to_html(paragraph):\n",
    "    text = \"\".join(convert_run_to_html(run) for run in paragraph.runs)\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    if is_list_item(paragraph):\n",
    "        return f\"<li>{text}</li>\"\n",
    "    style = getattr(paragraph.style, \"name\", \"\").lower()\n",
    "    if \"heading\" in style:\n",
    "        level = ''.join(filter(str.isdigit, style)) or \"2\"\n",
    "        return f\"<h{level}>{text}</h{level}>\"\n",
    "    return f\"<p>{text}</p>\"\n",
    "\n",
    "# ------------------- Extractors -------------------\n",
    "def extract_title(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "\n",
    "        # Detect \"Report Title\" subheading (numbered, bulleted, emoji, or plain)\n",
    "        if not capture and (\"report title\" in low):\n",
    "            capture = True\n",
    "            continue  # skip the heading line itself\n",
    "\n",
    "        # After capture → return first non-empty paragraph\n",
    "        if capture and text:\n",
    "            return text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ✅ Description (Introduction → stop before Report Summary/8.)\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list = [], False\n",
    "    start, stop = False, False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip().lower()\n",
    "\n",
    "        if not start and (\"introduction\" in text):\n",
    "            start = True\n",
    "\n",
    "        if start and not stop:\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "\n",
    "        if text.startswith(\"8.\") or \"report summary\" in text:\n",
    "            stop = True\n",
    "            break\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "# ✅ TOC (after Heading 9 / Table of Contents)\n",
    "def extract_toc(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list, capture = [], False, False\n",
    "    end_reached = False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "\n",
    "        # Start condition\n",
    "        if not capture and \"table of contents\" in low:\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "        if capture:\n",
    "            # End condition = capture \"List of Figures\" + its items, then stop\n",
    "            if \"list of figures\" in low:\n",
    "                html_part = paragraph_to_html(para)\n",
    "                if html_part:\n",
    "                    html_output.append(html_part)   # add heading \"List of Figures\"\n",
    "                end_reached = True\n",
    "                continue  # don't break yet, because its children may follow\n",
    "\n",
    "            if end_reached:\n",
    "                # If koi aur heading/subheading mil gaya to yahan break\n",
    "                style = getattr(para.style, \"name\", \"\").lower()\n",
    "                if \"heading\" in style or re.match(r\"^\\d+[\\.\\)]\\s\", text):\n",
    "                    break  \n",
    "\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "\n",
    "# ✅ extract description (Heading 1 → Heading 7 only)\n",
    "\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output = []\n",
    "    inside_list = False\n",
    "    capture = False  \n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        low = text.lower()\n",
    "\n",
    "        # --- Start Condition ---\n",
    "        if not capture and \"introduction and strategic context\" in low:\n",
    "            capture = True  \n",
    "\n",
    "        # --- Stop Condition ---\n",
    "        if capture and \"report summary, faqs, and seo schema\" in low:\n",
    "            break  \n",
    "\n",
    "        if capture:\n",
    "            html_part = paragraph_to_html(para)\n",
    "\n",
    "            if not html_part:\n",
    "                continue\n",
    "\n",
    "            if html_part.startswith(\"<li>\"):\n",
    "                if not inside_list:\n",
    "                    html_output.append(\"<ul>\")\n",
    "                    inside_list = True\n",
    "                html_output.append(html_part)\n",
    "            else:\n",
    "                if inside_list:\n",
    "                    html_output.append(\"</ul>\")\n",
    "                    inside_list = False\n",
    "                html_output.append(html_part)\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "# ✅ Methodology (FAQ Table or Paragraphs Qn:/A: format)\n",
    "def extract_methodology(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    faqs, q_count = [], 0\n",
    "\n",
    "    # --- Case 1: FAQ Table ---\n",
    "    for table in doc.tables:\n",
    "        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
    "        if \"question\" in headers and \"answer\" in headers:\n",
    "            for row in table.rows[1:]:\n",
    "                q_text = row.cells[0].text.strip()\n",
    "                a_text = row.cells[1].text.strip()\n",
    "                if q_text and a_text:\n",
    "                    q_count += 1\n",
    "                    faqs.append(\n",
    "                        f\"<p><strong>Q{q_count}: {html.escape(q_text)}</strong><br>\"\n",
    "                        f\"A{q_count}: {html.escape(a_text)}</p>\"\n",
    "                    )\n",
    "            if faqs:\n",
    "                return \"\\n\".join(faqs)  # return if table found\n",
    "\n",
    "    # --- Case 2 & 3: Text-based FAQs ---\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Start after \"Top 5 FAQs\" heading\n",
    "        if \"top 5 faqs\" in text.lower():\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "        if capture:\n",
    "            # ---- Case 3: Q and A in same paragraph ----\n",
    "            both_match = re.match(r\"Q\\d+[:.]\\s*(.*?)\\s*A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if both_match:\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(both_match.group(1).strip())}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(both_match.group(2).strip())}</p>\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # ---- Case 2: Q... in one para, A... in next ----\n",
    "            q_match = re.match(r\"Q\\d+[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if q_match:\n",
    "                current_q = q_match.group(1).strip()\n",
    "                continue\n",
    "\n",
    "            a_match = re.match(r\"A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if a_match and 'current_q' in locals():\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(current_q)}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(a_match.group(1).strip())}</p>\"\n",
    "                )\n",
    "                del current_q  # reset\n",
    "\n",
    "    return \"\\n\".join(faqs)\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Meta Description (first para after Introduction)\n",
    "def extract_meta_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"introduction\" in low):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture and text:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "# ✅ Detect new subheading (for SeoTitle/BreadcrumbText)\n",
    "def _is_new_subheading(text: str) -> bool:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return False\n",
    "    if text.startswith((\"📊\", \"❓\", \"🧩\")):\n",
    "        return True\n",
    "    if re.match(r\"^[A-Z](?:\\.\\d+)?\\.\\s\", text):\n",
    "        return True\n",
    "    if re.match(r\"^\\d+\\.\\s\", text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ✅ SeoTitle & BreadcrumbText (A.3. Headline block)\n",
    "def extract_seo_title_and_breadcrumb(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture, lines = False, []\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"a.3. headline\" in low or low.startswith(\"headline\")):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            if _is_new_subheading(text):\n",
    "                break\n",
    "            if text:\n",
    "                lines.append(text)\n",
    "                if len(lines) >= 2:\n",
    "                    break\n",
    "    seo_title = lines[0] if len(lines) >= 1 else \"\"\n",
    "    breadcrumb_text = lines[1] if len(lines) >= 2 else \"\"\n",
    "    return seo_title, breadcrumb_text\n",
    "\n",
    "# ------------------- Runner -------------------\n",
    "\n",
    "doc_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\extracted_docs\\Aerospace Floor Panel Market.docx\"\n",
    "title=extract_title(doc_path)\n",
    "description_html = extract_description(doc_path)\n",
    "toc_html = extract_toc(doc_path)\n",
    "methodology_html = extract_methodology(doc_path)\n",
    "meta = extract_meta_description(doc_path)\n",
    "seo_title, breadcrumb_text = extract_seo_title_and_breadcrumb(doc_path)\n",
    "\n",
    "# ✅ Save single file result in Excel\n",
    "df = pd.DataFrame([{\n",
    "    \"Title\":title,\n",
    "    \"Description\": description_html,\n",
    "    \"TOC\": toc_html,\n",
    "    \"Methodology\": methodology_html,\n",
    "    \"Meta Description\": meta,\n",
    "    \"SeoTitle\": seo_title,\n",
    "    \"BreadcrumbText\": breadcrumb_text\n",
    "}])\n",
    "\n",
    "output_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\SingleFile_Output9.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Done! Extracted data saved in {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77299efd",
   "metadata": {},
   "source": [
    "For Multiple Word File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import html\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------- Helpers -------------------\n",
    "def is_list_item(paragraph):\n",
    "    return paragraph._element.pPr is not None and paragraph._element.pPr.numPr is not None\n",
    "\n",
    "def convert_run_to_html(run):\n",
    "    text = html.escape(run.text)\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    if run.bold:\n",
    "        text = f\"<strong>{text}</strong>\"\n",
    "    if run.italic:\n",
    "        text = f\"<em>{text}</em>\"\n",
    "    if run.underline:\n",
    "        text = f\"<u>{text}</u>\"\n",
    "    return text\n",
    "\n",
    "def paragraph_to_html(paragraph):\n",
    "    text = \"\".join(convert_run_to_html(run) for run in paragraph.runs)\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    if is_list_item(paragraph):\n",
    "        return f\"<li>{text}</li>\"\n",
    "    style = getattr(paragraph.style, \"name\", \"\").lower()\n",
    "    if \"heading\" in style:\n",
    "        level = ''.join(filter(str.isdigit, style)) or \"2\"\n",
    "        return f\"<h{level}>{text}</h{level}>\"\n",
    "    return f\"<p>{text}</p>\"\n",
    "\n",
    "# ------------------- Extractors -------------------\n",
    "\n",
    "def extract_title(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"report title\" in low):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture and text:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list = [], False\n",
    "    start, stop = False, False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not start and \"introduction and strategic context\" in low:\n",
    "            start = True\n",
    "        if start and not stop:\n",
    "            if \"report summary, faqs, and seo schema\" in low:\n",
    "                stop = True\n",
    "                break\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "def extract_toc(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list, capture = [], False, False\n",
    "    end_reached = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and \"table of contents\" in low:\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            if \"list of figures\" in low:\n",
    "                html_part = paragraph_to_html(para)\n",
    "                if html_part:\n",
    "                    html_output.append(html_part)\n",
    "                end_reached = True\n",
    "                continue\n",
    "            if end_reached:\n",
    "                style = getattr(para.style, \"name\", \"\").lower()\n",
    "                if \"heading\" in style or re.match(r\"^\\d+[\\.\\)]\\s\", text):\n",
    "                    break  \n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "def extract_methodology(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    faqs, q_count = [], 0\n",
    "    for table in doc.tables:\n",
    "        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
    "        if \"question\" in headers and \"answer\" in headers:\n",
    "            for row in table.rows[1:]:\n",
    "                q_text = row.cells[0].text.strip()\n",
    "                a_text = row.cells[1].text.strip()\n",
    "                if q_text and a_text:\n",
    "                    q_count += 1\n",
    "                    faqs.append(\n",
    "                        f\"<p><strong>Q{q_count}: {html.escape(q_text)}</strong><br>\"\n",
    "                        f\"A{q_count}: {html.escape(a_text)}</p>\"\n",
    "                    )\n",
    "            if faqs:\n",
    "                return \"\\n\".join(faqs)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        if \"top 5 faqs\" in text.lower():\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            both_match = re.match(r\"Q\\d+[:.]\\s*(.*?)\\s*A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if both_match:\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(both_match.group(1).strip())}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(both_match.group(2).strip())}</p>\"\n",
    "                )\n",
    "                continue\n",
    "            q_match = re.match(r\"Q\\d+[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if q_match:\n",
    "                current_q = q_match.group(1).strip()\n",
    "                continue\n",
    "            a_match = re.match(r\"A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if a_match and 'current_q' in locals():\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(current_q)}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(a_match.group(1).strip())}</p>\"\n",
    "                )\n",
    "                del current_q\n",
    "    return \"\\n\".join(faqs)\n",
    "\n",
    "def extract_meta_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"introduction\" in low):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture and text:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "def _is_new_subheading(text: str) -> bool:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return False\n",
    "    if text.startswith((\"📊\", \"❓\", \"🧩\")):\n",
    "        return True\n",
    "    if re.match(r\"^[A-Z](?:\\.\\d+)?\\.\\s\", text):\n",
    "        return True\n",
    "    if re.match(r\"^\\d+\\.\\s\", text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_seo_title_and_breadcrumb(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture, lines = False, []\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"a.3. headline\" in low or low.startswith(\"headline\")):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            if _is_new_subheading(text):\n",
    "                break\n",
    "            if text:\n",
    "                lines.append(text)\n",
    "                if len(lines) >= 2:\n",
    "                    break\n",
    "    seo_title = lines[0] if len(lines) >= 1 else \"\"\n",
    "    breadcrumb_text = lines[1] if len(lines) >= 2 else \"\"\n",
    "    return seo_title, breadcrumb_text\n",
    "\n",
    "# ------------------- Runner for All Files -------------------\n",
    "\n",
    "folder_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\extracted_docs\"\n",
    "output_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\AllFiles_Output.xlsx\"\n",
    "\n",
    "all_data = []\n",
    "for file in os.listdir(folder_path):\n",
    "    if not file.endswith(\".docx\") or file.startswith(\"~$\"):\n",
    "        continue\n",
    "    doc_path = os.path.join(folder_path, file)\n",
    "    print(f\"Processing: {file}\")\n",
    "\n",
    "    title = extract_title(doc_path)\n",
    "    description_html = extract_description(doc_path)\n",
    "    toc_html = extract_toc(doc_path)\n",
    "    methodology_html = extract_methodology(doc_path)\n",
    "    meta = extract_meta_description(doc_path)\n",
    "    seo_title, breadcrumb_text = extract_seo_title_and_breadcrumb(doc_path)\n",
    "\n",
    "    all_data.append({\n",
    "        \"File\": file,\n",
    "        \"Title\": title,\n",
    "        \"Description\": description_html,\n",
    "        \"TOC\": toc_html,\n",
    "        \"Methodology\": methodology_html,\n",
    "        \"Meta Description\": meta,\n",
    "        \"SeoTitle\": seo_title,\n",
    "        \"BreadcrumbText\": breadcrumb_text\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"✅ Done! Extracted data saved in {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
