{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b47f827",
   "metadata": {},
   "source": [
    "For Single Word File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd82f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done! Extracted data saved in C:\\Users\\Vishnu\\Documents\\extracted_docs\\SingleFile.xlsx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import html\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------- Helpers -------------------\n",
    "def is_list_item(paragraph):\n",
    "    return paragraph._element.pPr is not None and paragraph._element.pPr.numPr is not None\n",
    "\n",
    "def convert_run_to_html(run):\n",
    "    text = html.escape(run.text)\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    if run.bold:\n",
    "        text = f\"<strong>{text}</strong>\"\n",
    "    if run.italic:\n",
    "        text = f\"<em>{text}</em>\"\n",
    "    if run.underline:\n",
    "        text = f\"<u>{text}</u>\"\n",
    "    return text\n",
    "\n",
    "def paragraph_to_html(paragraph):\n",
    "    text = \"\".join(convert_run_to_html(run) for run in paragraph.runs)\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    if is_list_item(paragraph):\n",
    "        return f\"<li>{text}</li>\"\n",
    "    style = getattr(paragraph.style, \"name\", \"\").lower()\n",
    "    if \"heading\" in style:\n",
    "        level = ''.join(filter(str.isdigit, style)) or \"2\"\n",
    "        return f\"<h{level}>{text}</h{level}>\"\n",
    "    return f\"<p>{text}</p>\"\n",
    "\n",
    "# ------------------- Extractors -------------------\n",
    "def extract_title(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "\n",
    "        # Detect \"Report Title\" subheading (numbered, bulleted, emoji, or plain)\n",
    "        if not capture and (\"report title\" in low):\n",
    "            capture = True\n",
    "            continue  # skip the heading line itself\n",
    "\n",
    "        # After capture â†’ return first non-empty paragraph\n",
    "        if capture and text:\n",
    "            return text\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# âœ… Description (Introduction â†’ stop before Report Summary/8.)\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list = [], False\n",
    "    start, stop = False, False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip().lower()\n",
    "\n",
    "        if not start and (\"introduction\" in text):\n",
    "            start = True\n",
    "\n",
    "        if start and not stop:\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "\n",
    "        if text.startswith(\"8.\") or \"report summary\" in text:\n",
    "            stop = True\n",
    "            break\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "# âœ… TOC (after Heading 9 / Table of Contents)\n",
    "def extract_toc(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list, capture = [], False, False\n",
    "    end_reached = False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "\n",
    "        # Start condition\n",
    "        if not capture and \"table of contents\" in low:\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "        if capture:\n",
    "            # End condition = capture \"List of Figures\" + its items, then stop\n",
    "            if \"list of figures\" in low:\n",
    "                html_part = paragraph_to_html(para)\n",
    "                if html_part:\n",
    "                    html_output.append(html_part)   # add heading \"List of Figures\"\n",
    "                end_reached = True\n",
    "                continue  # don't break yet, because its children may follow\n",
    "\n",
    "            if end_reached:\n",
    "                # If koi aur heading/subheading mil gaya to yahan break\n",
    "                style = getattr(para.style, \"name\", \"\").lower()\n",
    "                if \"heading\" in style or re.match(r\"^\\d+[\\.\\)]\\s\", text):\n",
    "                    break  \n",
    "\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "\n",
    "# âœ… extract description (Heading 1 â†’ Heading 7 only)\n",
    "\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output = []\n",
    "    inside_list = False\n",
    "    capture = False  \n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        low = text.lower()\n",
    "\n",
    "        # --- Start Condition ---\n",
    "        if not capture and \"introduction and strategic context\" in low:\n",
    "            capture = True  \n",
    "\n",
    "        # --- Stop Condition ---\n",
    "        if capture and \"report summary, faqs, and seo schema\" in low:\n",
    "            break  \n",
    "\n",
    "        if capture:\n",
    "            html_part = paragraph_to_html(para)\n",
    "\n",
    "            if not html_part:\n",
    "                continue\n",
    "\n",
    "            if html_part.startswith(\"<li>\"):\n",
    "                if not inside_list:\n",
    "                    html_output.append(\"<ul>\")\n",
    "                    inside_list = True\n",
    "                html_output.append(html_part)\n",
    "            else:\n",
    "                if inside_list:\n",
    "                    html_output.append(\"</ul>\")\n",
    "                    inside_list = False\n",
    "                html_output.append(html_part)\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "\n",
    "    return \"\\n\".join(html_output)\n",
    "\n",
    "# âœ… Methodology (FAQ Table or Paragraphs Qn:/A: format)\n",
    "def extract_methodology(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    faqs, q_count = [], 0\n",
    "\n",
    "    # --- Case 1: FAQ Table ---\n",
    "    for table in doc.tables:\n",
    "        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
    "        if \"question\" in headers and \"answer\" in headers:\n",
    "            for row in table.rows[1:]:\n",
    "                q_text = row.cells[0].text.strip()\n",
    "                a_text = row.cells[1].text.strip()\n",
    "                if q_text and a_text:\n",
    "                    q_count += 1\n",
    "                    faqs.append(\n",
    "                        f\"<p><strong>Q{q_count}: {html.escape(q_text)}</strong><br>\"\n",
    "                        f\"A{q_count}: {html.escape(a_text)}</p>\"\n",
    "                    )\n",
    "            if faqs:\n",
    "                return \"\\n\".join(faqs)  # return if table found\n",
    "\n",
    "    # --- Case 2 & 3: Text-based FAQs ---\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Start after \"Top 5 FAQs\" heading\n",
    "        if \"top 5 faqs\" in text.lower():\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "        if capture:\n",
    "            # ---- Case 3: Q and A in same paragraph ----\n",
    "            both_match = re.match(r\"Q\\d+[:.]\\s*(.*?)\\s*A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if both_match:\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(both_match.group(1).strip())}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(both_match.group(2).strip())}</p>\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # ---- Case 2: Q... in one para, A... in next ----\n",
    "            q_match = re.match(r\"Q\\d+[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if q_match:\n",
    "                current_q = q_match.group(1).strip()\n",
    "                continue\n",
    "\n",
    "            a_match = re.match(r\"A\\d*[:.]\\s*(.*)\", text, re.IGNORECASE)\n",
    "            if a_match and 'current_q' in locals():\n",
    "                q_count += 1\n",
    "                faqs.append(\n",
    "                    f\"<p><strong>Q{q_count}: {html.escape(current_q)}</strong><br>\"\n",
    "                    f\"A{q_count}: {html.escape(a_match.group(1).strip())}</p>\"\n",
    "                )\n",
    "                del current_q  # reset\n",
    "\n",
    "    return \"\\n\".join(faqs)\n",
    "\n",
    "\n",
    "\n",
    "# âœ… Meta Description (first para after Introduction)\n",
    "def extract_meta_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"introduction\" in low):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture and text:\n",
    "            return text\n",
    "    return \"\"\n",
    "\n",
    "# âœ… Detect new subheading (for SeoTitle/BreadcrumbText)\n",
    "def _is_new_subheading(text: str) -> bool:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return False\n",
    "    if text.startswith((\"ðŸ“Š\", \"â“\", \"ðŸ§©\")):\n",
    "        return True\n",
    "    if re.match(r\"^[A-Z](?:\\.\\d+)?\\.\\s\", text):\n",
    "        return True\n",
    "    if re.match(r\"^\\d+\\.\\s\", text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# âœ… SeoTitle & BreadcrumbText (A.3. Headline block)\n",
    "def extract_seo_title_and_breadcrumb(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture, lines = False, []\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"a.3. headline\" in low or low.startswith(\"headline\")):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            if _is_new_subheading(text):\n",
    "                break\n",
    "            if text:\n",
    "                lines.append(text)\n",
    "                if len(lines) >= 2:\n",
    "                    break\n",
    "    seo_title = lines[0] if len(lines) >= 1 else \"\"\n",
    "    breadcrumb_text = lines[1] if len(lines) >= 2 else \"\"\n",
    "    return seo_title, breadcrumb_text\n",
    "\n",
    "# ------------------- Runner -------------------\n",
    "\n",
    "doc_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\extracted_docs\\Aerial Refueling System Market.docx\"\n",
    "title=extract_title(doc_path)\n",
    "description_html = extract_description(doc_path)\n",
    "toc_html = extract_toc(doc_path)\n",
    "methodology_html = extract_methodology(doc_path)\n",
    "meta = extract_meta_description(doc_path)\n",
    "seo_title, breadcrumb_text = extract_seo_title_and_breadcrumb(doc_path)\n",
    "\n",
    "# âœ… Save single file result in Excel\n",
    "df = pd.DataFrame([{\n",
    "    \"Title\":title,\n",
    "    \"Description\": description_html,\n",
    "    \"TOC\": toc_html,\n",
    "    \"Methodology\": methodology_html,\n",
    "    \"Meta Description\": meta,\n",
    "    \"SeoTitle\": seo_title,\n",
    "    \"BreadcrumbText\": breadcrumb_text\n",
    "}])\n",
    "\n",
    "output_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\SingleFile.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Done! Extracted data saved in {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77299efd",
   "metadata": {},
   "source": [
    "For Multiple Word File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "# ------------------- Helpers -------------------\n",
    "DASH = \"â€“\"  # en-dash for year ranges\n",
    "\n",
    "HEADER_LINE_RE = re.compile(\n",
    "    r\"\"\"^\\s*\n",
    "        (?:[A-Za-z]\\.)?\n",
    "        (?:\\d+(?:\\.\\d+)*)?\n",
    "        [\\.\\)]?\\s*\n",
    "        (?:report\\s*title|full\\s*title|full\\s*report\\s*title|title\\s*\\(long[-\\s]*form\\))\n",
    "        [\\s:â€“-]*$\n",
    "    \"\"\", re.I | re.X\n",
    ")\n",
    "\n",
    "def _inline_title(text: str) -> str:\n",
    "    m = re.split(r\"[:\\-â€“]\", text, maxsplit=1)\n",
    "    if len(m) > 1:\n",
    "        right = m[1].strip()\n",
    "        if right and not HEADER_LINE_RE.match(right):\n",
    "            return right\n",
    "    return \"\"\n",
    "\n",
    "def _year_range_present(text: str) -> bool:\n",
    "    return bool(re.search(r\"20\\d{2}\\s*[\\-â€“]\\s*20\\d{2}\", text))\n",
    "\n",
    "def _ensure_filename_start_and_year(title: str, filename: str) -> str:\n",
    "    if not title.lower().startswith(filename.lower()):\n",
    "        title = f\"{filename} {title}\"\n",
    "    if not _year_range_present(title):\n",
    "        title = f\"{title} {DASH}2024â€“2030\"\n",
    "    return _norm(title)\n",
    "\n",
    "def _remove_emojis(text: str) -> str:\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\" \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(\"\", text)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    s = _remove_emojis(s or \"\")\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip())\n",
    "\n",
    "# ------------------- Convert Paragraph to HTML -------------------\n",
    "def paragraph_to_html(para):\n",
    "    \"\"\"Convert a docx paragraph into HTML with basic formatting.\"\"\"\n",
    "    text = para.text.strip()\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Check if it's a list item\n",
    "    if para.style.name.lower().startswith(\"list\"):\n",
    "        return f\"<li>{text}</li>\"\n",
    "    \n",
    "    text = _remove_emojis(text)\n",
    "\n",
    "    # Headings\n",
    "    if para.style.name.startswith(\"Heading\"):\n",
    "        level = para.style.name.replace(\"Heading\", \"\").strip()\n",
    "        level = int(level) if level.isdigit() else 2\n",
    "        return f\"<h{level}>{text}</h{level}>\"\n",
    "\n",
    "    # Normal paragraph\n",
    "    return f\"<p>{text}</p>\"\n",
    "# ----------------------------------------------------Extract Title----------------------------\n",
    "def extract_title(docx_path: str) -> str:\n",
    "    from docx import Document\n",
    "    import os, re\n",
    "\n",
    "    doc = Document(docx_path)\n",
    "    filename = os.path.splitext(os.path.basename(docx_path))[0]\n",
    "    filename_low = filename.lower()\n",
    "\n",
    "    blocks = [(p, (p.text or \"\").strip()) for p in doc.paragraphs if (p.text or \"\").strip()]\n",
    "\n",
    "    capture = False\n",
    "    # --- Priority 1: Explicit \"Report Title\" / \"Long-Form\" ---\n",
    "    for _, text in blocks:\n",
    "        if capture:\n",
    "            return _ensure_filename_start_and_year(text, filename)\n",
    "        if HEADER_LINE_RE.match(text):\n",
    "            inline = _inline_title(text)\n",
    "            if inline:\n",
    "                return _ensure_filename_start_and_year(inline, filename)\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "    # --- Priority 2: Tables ---\n",
    "    for table in doc.tables:\n",
    "        for r_idx, row in enumerate(table.rows):\n",
    "            for c_idx, cell in enumerate(row.cells):\n",
    "                cell_text = (cell.text or \"\").strip().lower()\n",
    "                if not cell_text:\n",
    "                    continue\n",
    "                if \"report title\" in cell_text or \"full title\" in cell_text or \"full report title\" in cell_text:\n",
    "                    if c_idx + 1 < len(row.cells):\n",
    "                        nxt = row.cells[c_idx+1].text.strip()\n",
    "                        if nxt:\n",
    "                            return _ensure_filename_start_and_year(nxt, filename)\n",
    "                    if r_idx + 1 < len(table.rows):\n",
    "                        nxt = table.rows[r_idx+1].cells[c_idx].text.strip()\n",
    "                        if nxt:\n",
    "                            return _ensure_filename_start_and_year(nxt, filename)\n",
    "                        if c_idx + 1 < len(table.rows[r_idx+1].cells):\n",
    "                            nxt2 = table.rows[r_idx+1].cells[c_idx+1].text.strip()\n",
    "                            if nxt2:\n",
    "                                return _ensure_filename_start_and_year(nxt2, filename)\n",
    "\n",
    "    # --- Priority 3: \"Full Title\" inline variations ---\n",
    "    for _, text in blocks:\n",
    "        low = text.lower()\n",
    "        if low.startswith(\"full report title\") or low.startswith(\"full title\"):\n",
    "            inline = _inline_title(text)\n",
    "            if inline:\n",
    "                return _ensure_filename_start_and_year(inline, filename)\n",
    "\n",
    "    # --- Priority 4: Fallback (only if nothing above matched) ---\n",
    "    skip_words = (\"strategically\", \"introduction\", \"context\")\n",
    "    for _, t in blocks:\n",
    "        tt = _norm(t)\n",
    "        low = tt.lower()\n",
    "        if any(sw in low for sw in skip_words):\n",
    "            continue\n",
    "        if low.startswith(\"the global\"):\n",
    "            continue\n",
    "        if \"table of contents\" in low or \"toc\" in low:\n",
    "            continue\n",
    "        if \"list of tables\" in low or \"list of figures\" in low:\n",
    "            continue\n",
    "        if _year_range_present(tt) and any(word in low for word in filename_low.split()):\n",
    "            return _ensure_filename_start_and_year(tt, filename)\n",
    "\n",
    "    return \"Title Not Available\"\n",
    "\n",
    "# ------------------- Extract Description -------------------\n",
    "def extract_description(docx_path):\n",
    "    from docx import Document\n",
    "    doc = Document(docx_path)\n",
    "    html_output = []\n",
    "    capture, inside_list = False, False  \n",
    "\n",
    "    def run_to_html(run):\n",
    "        \"\"\"Convert bold/italic text to HTML span.\"\"\"\n",
    "        text = run.text.strip()\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        if run.bold and run.italic:\n",
    "            return f\"<b><i>{text}</i></b>\"\n",
    "        elif run.bold:\n",
    "            return f\"<b>{text}</b>\"\n",
    "        elif run.italic:\n",
    "            return f\"<i>{text}</i>\"\n",
    "        return text\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        low = text.lower()\n",
    "\n",
    "        # --- Start condition ---\n",
    "        if not capture and (\n",
    "            \"introduction and strategic context\" in low\n",
    "            or text.startswith(\"the global\")\n",
    "            or \"market will witness\" in low\n",
    "        ):\n",
    "            capture = True\n",
    "            html_output.append(\"<h2>Introduction and Strategic Context</h2>\")\n",
    "\n",
    "        # --- Stop condition ---\n",
    "        if capture and \"report summary, faqs, and seo schema\" in low:\n",
    "            break  \n",
    "\n",
    "        if capture:\n",
    "            # Convert runs (bold/italic parts) to inline HTML\n",
    "            content = \"\".join(run_to_html(run) for run in para.runs if run.text.strip())\n",
    "\n",
    "            # Heading handling\n",
    "            if para.style.name.startswith(\"Heading\"):\n",
    "                level = para.style.name.replace(\"Heading\", \"\").strip()\n",
    "                level = int(level) if level.isdigit() else 2\n",
    "                html_output.append(f\"<h{level}>{content}</h{level}>\")\n",
    "                continue\n",
    "\n",
    "            # List handling\n",
    "            if \"list\" in para.style.name.lower():\n",
    "                if not inside_list:\n",
    "                    html_output.append(\"<ul>\")\n",
    "                    inside_list = True\n",
    "                html_output.append(f\"<li>{content}</li>\")\n",
    "                continue\n",
    "            else:\n",
    "                if inside_list:\n",
    "                    html_output.append(\"</ul>\")\n",
    "                    inside_list = False\n",
    "\n",
    "            # Normal paragraph\n",
    "            html_output.append(f\"<p>{content}</p>\")\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return _remove_emojis(\"\\n\".join(html_output))\n",
    "\n",
    "# -------------------------------TOC (after Heading 9 / Table of Contents)--------------------------------------\n",
    "def extract_toc(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output, inside_list, capture = [], False, False\n",
    "    end_reached = False\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "\n",
    "        # Start condition\n",
    "        if not capture and \"table of contents\" in low:\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "        if capture:\n",
    "            # End condition = capture \"List of Figures\" + its items, then stop\n",
    "            if \"list of figures\" in low:\n",
    "                html_part = paragraph_to_html(para)\n",
    "                if html_part:\n",
    "                    html_output.append(html_part)   # add heading \"List of Figures\"\n",
    "                end_reached = True\n",
    "                continue  # don't break yet, because its children may follow\n",
    "\n",
    "            if end_reached:\n",
    "                style = getattr(para.style, \"name\",\"\").lower()\n",
    "                if \"heading\" in style or re.match(r\"^\\d+[\\.\\)]\\s\", text):\n",
    "                    break  \n",
    "\n",
    "            html_part = paragraph_to_html(para)\n",
    "            if html_part:\n",
    "                if html_part.startswith(\"<li>\"):\n",
    "                    if not inside_list:\n",
    "                        html_output.append(\"<ul>\")\n",
    "                        inside_list = True\n",
    "                    html_output.append(html_part)\n",
    "                else:\n",
    "                    if inside_list:\n",
    "                        html_output.append(\"</ul>\")\n",
    "                        inside_list = False\n",
    "                    html_output.append(html_part)\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return _remove_emojis(\"\".join(html_output).strip())\n",
    "\n",
    "# ---------------------------------------Meta Discription---------------------------------------\n",
    "def extract_meta_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    capture = False\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        low = text.lower()\n",
    "        if not capture and (\"introduction\" in low):\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture and text:\n",
    "            return text\n",
    "    return \"\"\n",
    "# --------------------------------------------SEO title-------------------------------------------------------------\n",
    "def extract_seo_title(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    file_name = os.path.splitext(os.path.basename(docx_path))[0]  # File name without extension\n",
    "    \n",
    "    revenue_forecast = \"\"\n",
    "\n",
    "    # --- Check tables for Report Coverage ---\n",
    "    for table in doc.tables:\n",
    "        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
    "\n",
    "        if \"report attribute\" in headers and \"details\" in headers:\n",
    "            attr_idx = headers.index(\"report attribute\")\n",
    "            details_idx = headers.index(\"details\")\n",
    "\n",
    "            for row in table.rows[1:]:\n",
    "                attr = row.cells[attr_idx].text.strip().lower()\n",
    "                details = row.cells[details_idx].text.strip()\n",
    "\n",
    "                if \"revenue forecast in 2030\" in attr:\n",
    "                    # replace USD with $\n",
    "                    revenue_forecast = details.replace(\"USD\", \"$\").strip()\n",
    "                    break\n",
    "\n",
    "    if revenue_forecast:\n",
    "        seo_title = f\"{file_name} Size ({revenue_forecast}) 2030\"\n",
    "    else:\n",
    "        seo_title = file_name  # fallback\n",
    "\n",
    "    return seo_title\n",
    "# -----------------------------------------------BreadCrumb Text----------------------------------------\n",
    "def extract_breadcrumb_text(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    file_name = os.path.splitext(os.path.basename(docx_path))[0]  # File name without extension\n",
    "    \n",
    "    revenue_forecast = \"\"\n",
    "\n",
    "    # --- Check tables for Report Coverage ---\n",
    "    for table in doc.tables:\n",
    "        headers = [cell.text.strip().lower() for cell in table.rows[0].cells]\n",
    "\n",
    "        if \"report attribute\" in headers and \"details\" in headers:\n",
    "            attr_idx = headers.index(\"report attribute\")\n",
    "            details_idx = headers.index(\"details\")\n",
    "\n",
    "            for row in table.rows[1:]:\n",
    "                attr = row.cells[attr_idx].text.strip().lower()\n",
    "                details = row.cells[details_idx].text.strip()\n",
    "\n",
    "                if \"revenue forecast in 2030\" in attr:\n",
    "                    # replace USD with $\n",
    "                    revenue_forecast = details.replace(\"USD\", \"$\").strip()\n",
    "                    break\n",
    "\n",
    "    if revenue_forecast:\n",
    "        seo_title = f\"{file_name} Report 2030\"\n",
    "    else:\n",
    "        seo_title = file_name  # fallback\n",
    "\n",
    "    return seo_title\n",
    "\n",
    "# ---------------------------------------------SkuCode-Extraction------------------------------\n",
    "def extract_sku_code(docx_path):\n",
    "    filename = os.path.basename(docx_path)\n",
    "    sku_code = os.path.splitext(filename)[0].lower()\n",
    "    return sku_code\n",
    "# ---------------------------------------------URLRP------------------------------\n",
    "def extract_sku_url(docx_path):\n",
    "    filename = os.path.basename(docx_path)\n",
    "    sku_code = os.path.splitext(filename)[0].lower()\n",
    "    return sku_code\n",
    "\n",
    "# ---------------------------------------------BreadCrumb Schema----------------------------\n",
    "def extract_breadcrumb_schema(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]\n",
    "\n",
    "    capture = False\n",
    "    breadcrumb_data = []\n",
    "\n",
    "    for text in paragraphs:\n",
    "        low = text.lower()\n",
    "\n",
    "        # Start condition â†’ JSON block must start with {\n",
    "        if not capture and text.strip().startswith(\"{\"):\n",
    "            capture = True\n",
    "        \n",
    "        # End condition â†’ stop when json copy or faq schema heading found\n",
    "        if capture and (\"json copy\" in low or \"faq schema\" in low):\n",
    "            break\n",
    "\n",
    "        # Collect JSON block only\n",
    "        if capture:\n",
    "            breadcrumb_data.append(text)\n",
    "\n",
    "    return \"\".join(breadcrumb_data).strip()\n",
    "# --------------------------------Schema 2-----------------------\n",
    "def _get_text(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\n\".join(p.text for p in doc.paragraphs if p.text and p.text.strip())\n",
    "\n",
    "def _extract_json_block(text, type_name):\n",
    "    # find \"@type\": \"BreadcrumbList\" OR \"@type\": \"FAQPage\"\n",
    "    pat = re.compile(r'\"@type\"\\s*:\\s*\"' + re.escape(type_name) + r'\"')\n",
    "    m = pat.search(text)\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    start_idx = text.rfind(\"{\", 0, m.start())\n",
    "    if start_idx == -1:\n",
    "        return \"\"\n",
    "    depth, i, n = 0, start_idx, len(text)\n",
    "    block_chars = []\n",
    "    while i < n:\n",
    "        ch = text[i]\n",
    "        block_chars.append(ch)\n",
    "        if ch == \"{\":\n",
    "            depth += 1\n",
    "        elif ch == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                break\n",
    "        i += 1\n",
    "    return \"\".join(block_chars).strip()\n",
    "\n",
    "def extract_breadcrumb_schema(docx_path):\n",
    "    text = _get_text(docx_path)\n",
    "    return _extract_json_block(text, \"BreadcrumbList\")\n",
    "\n",
    "def extract_faq_schema(docx_path):\n",
    "    text = _get_text(docx_path)\n",
    "    return _extract_json_block(text, \"FAQPage\")\n",
    "# -----------------------------------------------------------------\n",
    "import json\n",
    "import html\n",
    "def extract_methodology_from_faqschema(docx_path):\n",
    "    faq_schema_str = extract_faq_schema(docx_path)  \n",
    "    if not faq_schema_str:\n",
    "        return \"\"   # agar schema na mile to blank\n",
    "    \n",
    "    try:\n",
    "        faq_data = json.loads(faq_schema_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"   # agar JSON format galat hai\n",
    "    \n",
    "    faqs = []\n",
    "    q_count = 0\n",
    "    for item in faq_data.get(\"mainEntity\", []):\n",
    "        q_count += 1\n",
    "        question = item.get(\"name\", \"\").strip()\n",
    "        answer = item.get(\"acceptedAnswer\", {}).get(\"text\", \"\").strip()\n",
    "        if question and answer:\n",
    "            faqs.append(\n",
    "                f\"<p><strong>Q{q_count}: {html.escape(question)}</strong><br>\"\n",
    "                f\"A{q_count}: {html.escape(answer)}</p>\"\n",
    "            )\n",
    "    \n",
    "    return \"\\n\".join(faqs)\n",
    "# --------------------------------------------Report Coverage Table-----------------------------------\n",
    "def extract_report_coverage_table_with_style(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "\n",
    "    for table in doc.tables:\n",
    "        # check if this is Report Coverage Table\n",
    "        first_row_text = \" \".join([c.text.strip().lower() for c in table.rows[0].cells])\n",
    "        if \"report attribute\" in first_row_text or \"report coverage table\" in first_row_text:\n",
    "            html = []\n",
    "            # --- Add heading ---\n",
    "            html.append('<h2><strong>7.1. Report Coverage Table</strong></h2>')\n",
    "            html.append('<table cellspacing=\"0\" style=\"border-collapse:collapse; width:100%\"><tbody>')\n",
    "\n",
    "            for r_idx, row in enumerate(table.rows):\n",
    "                html.append(\"<tr>\")\n",
    "                for c_idx, cell in enumerate(row.cells):\n",
    "                    text = cell.text.strip()\n",
    "\n",
    "                    # alternate row background\n",
    "                    bg = \"#deeaf6\" if r_idx % 2 == 1 else \"#ffffff\"\n",
    "                    # header row style\n",
    "                    if r_idx == 0:\n",
    "                        bg = \"#5b9bd5\"\n",
    "\n",
    "                    # td style\n",
    "                    td_style = (\n",
    "                        f\"background-color:{bg}; \"\n",
    "                        \"border:1px solid #9cc2e5; vertical-align:top; padding:4px;\"\n",
    "                        \"width:263px\" if c_idx == 0 else\n",
    "                        f\"background-color:{bg}; border:1px solid #9cc2e5; vertical-align:top; padding:4px; width:303px\"\n",
    "                    )\n",
    "\n",
    "                    # wrap text inside <p>\n",
    "                    html.append(f'<td style=\"{td_style}\"><p><strong>{text}</strong></p></td>' if c_idx == 0 or r_idx==0 else f'<td style=\"{td_style}\"><p>{text}</p></td>')\n",
    "                html.append(\"</tr>\")\n",
    "            html.append(\"</tbody></table>\")\n",
    "            return \"\\n\".join(html)\n",
    "\n",
    "    return \"\"\n",
    "# ------------------------------------------------------Merger--------------------------------------------------\n",
    "def merge_description_and_coverage(docx_path):\n",
    "    try:\n",
    "        desc_html = extract_description(docx_path) or \"\"\n",
    "        coverage_html = extract_report_coverage_table_with_style(docx_path) or \"\"\n",
    "        merged_html = desc_html + \"\\n\\n\" + coverage_html if (desc_html or coverage_html) else \"\"\n",
    "        return merged_html\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "\n",
    "# ------------------- Run Extraction -------------------\n",
    "folder_path = r\"C:\\Users\\Vishnu\\Desktop\\oldcontent\\23 june\\23 june\"\n",
    "output_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\Extraction_New_Title_Old.xlsx\"\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if not file.endswith(\".docx\") or file.startswith(\"~$\"):\n",
    "        continue\n",
    "\n",
    "    doc_path = os.path.join(folder_path, file)\n",
    "    print(f\"Processing: {file}\")\n",
    "    title = extract_title(doc_path)\n",
    "    description_html = extract_description(doc_path)\n",
    "    toc=extract_toc(doc_path)\n",
    "    methodology=extract_methodology_from_faqschema(doc_path)\n",
    "    # methodology_html = extract_methodology(doc_path)\n",
    "    seo_title = extract_seo_title(doc_path)\n",
    "    breadcrumb_text = extract_breadcrumb_text(doc_path)\n",
    "    skucode = extract_sku_code(doc_path)\n",
    "    urlrp = extract_sku_url(doc_path)\n",
    "    breadcrumb_schema=extract_breadcrumb_schema(doc_path)\n",
    "    meta=extract_meta_description(doc_path)\n",
    "    schema2=extract_faq_schema(doc_path)\n",
    "    report=extract_report_coverage_table_with_style(doc_path)\n",
    "    merge=merge_description_and_coverage(doc_path)\n",
    "\n",
    "    all_data.append({\n",
    "        \"File\": file,\n",
    "        \"Title\": title,\n",
    "        \"Description\": description_html,\n",
    "        \"TOC\":toc,\n",
    "        \"Segmentation\":\"<p>.</p>\",\n",
    "        \"Methodology\":methodology,\n",
    "        \"Publish_Date\":date.today().strftime(\"%B %Y\"),\n",
    "        \"Currency\":\"USD\",\n",
    "        \"Single Price\": 4485,\n",
    "        \"Corporate Price\": 6449,\n",
    "        \"skucode\": skucode,\n",
    "        \"Total Page\":\"\",\n",
    "        \"Date\": date.today().strftime(\"%Y-%m-%d\"),  # always today's date\n",
    "        \"urlNp\": urlrp,\n",
    "        \"Meta Discription\":meta,\n",
    "        \"Meta Keys\":\"\",\n",
    "        \"Base Year\":\"2024\",\n",
    "        \"history\":\"2019-2023\",\n",
    "        \"Enterprise Price\": 8339,\n",
    "        \"SEOTITLE\": seo_title,\n",
    "        \"BreadCrumb Text\": breadcrumb_text,\n",
    "        \"Schema 1\":breadcrumb_schema,\n",
    "        \"Schema 2\":schema2,\n",
    "        \"Report\":report,\n",
    "        \"Discription\":merge\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Done! Extracted data saved in {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40d083",
   "metadata": {},
   "source": [
    "If Cell Limit is Crossed in extract_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import json\n",
    "import html\n",
    "\n",
    "# ------------------- Helpers -------------------\n",
    "DASH = \"â€“\"  # en-dash for year ranges\n",
    "EXCEL_CELL_LIMIT = 32767  # Excel max char limit per cell\n",
    "\n",
    "def split_into_excel_cells(text, limit=EXCEL_CELL_LIMIT):\n",
    "    \"\"\"Split text into chunks that fit within Excel cell limit.\"\"\"\n",
    "    if not text:\n",
    "        return [\"\"]\n",
    "    return [text[i:i+limit] for i in range(0, len(text), limit)]\n",
    "\n",
    "HEADER_LINE_RE = re.compile(\n",
    "    r\"\"\"^\\s*\n",
    "        (?:[A-Za-z]\\.)?\n",
    "        (?:\\d+(?:\\.\\d+)*)?\n",
    "        [\\.\\)]?\\s*\n",
    "        (?:report\\s*title|full\\s*title|full\\s*report\\s*title|title\\s*\\(long[-\\s]*form\\))\n",
    "        [\\s:â€“-]*$\n",
    "    \"\"\", re.I | re.X\n",
    ")\n",
    "\n",
    "def _inline_title(text: str) -> str:\n",
    "    m = re.split(r\"[:\\-â€“]\", text, maxsplit=1)\n",
    "    if len(m) > 1:\n",
    "        right = m[1].strip()\n",
    "        if right and not HEADER_LINE_RE.match(right):\n",
    "            return right\n",
    "    return \"\"\n",
    "\n",
    "def _year_range_present(text: str) -> bool:\n",
    "    return bool(re.search(r\"20\\d{2}\\s*[\\-â€“]\\s*20\\d{2}\", text))\n",
    "\n",
    "def _ensure_filename_start_and_year(title: str, filename: str) -> str:\n",
    "    if not title.lower().startswith(filename.lower()):\n",
    "        title = f\"{filename} {title}\"\n",
    "    if not _year_range_present(title):\n",
    "        title = f\"{title} {DASH}2024â€“2030\"\n",
    "    return _norm(title)\n",
    "\n",
    "def _remove_emojis(text: str) -> str:\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\" \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(\"\", text)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    s = _remove_emojis(s or \"\")\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip())\n",
    "\n",
    "# ------------------- Convert Paragraph to HTML -------------------\n",
    "def paragraph_to_html(para):\n",
    "    text = para.text.strip()\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    if para.style.name.lower().startswith(\"list\"):\n",
    "        return f\"<li>{text}</li>\"\n",
    "\n",
    "    text = _remove_emojis(text)\n",
    "\n",
    "    if para.style.name.startswith(\"Heading\"):\n",
    "        level = para.style.name.replace(\"Heading\", \"\").strip()\n",
    "        level = int(level) if level.isdigit() else 2\n",
    "        return f\"<h{level}>{text}</h{level}>\"\n",
    "\n",
    "    return f\"<p>{text}</p>\"\n",
    "\n",
    "# ----------------------------------------------------Extract Title----------------------------\n",
    "def extract_title(docx_path: str) -> str:\n",
    "    doc = Document(docx_path)\n",
    "    filename = os.path.splitext(os.path.basename(docx_path))[0]\n",
    "    filename_low = filename.lower()\n",
    "    blocks = [(p, (p.text or \"\").strip()) for p in doc.paragraphs if (p.text or \"\").strip()]\n",
    "\n",
    "    capture = False\n",
    "    for _, text in blocks:\n",
    "        if capture:\n",
    "            return _ensure_filename_start_and_year(text, filename)\n",
    "        if HEADER_LINE_RE.match(text):\n",
    "            inline = _inline_title(text)\n",
    "            if inline:\n",
    "                return _ensure_filename_start_and_year(inline, filename)\n",
    "            capture = True\n",
    "            continue\n",
    "\n",
    "    for table in doc.tables:\n",
    "        for r_idx, row in enumerate(table.rows):\n",
    "            for c_idx, cell in enumerate(row.cells):\n",
    "                cell_text = (cell.text or \"\").strip().lower()\n",
    "                if not cell_text:\n",
    "                    continue\n",
    "                if \"report title\" in cell_text or \"full title\" in cell_text or \"full report title\" in cell_text:\n",
    "                    if c_idx + 1 < len(row.cells):\n",
    "                        nxt = row.cells[c_idx+1].text.strip()\n",
    "                        if nxt:\n",
    "                            return _ensure_filename_start_and_year(nxt, filename)\n",
    "                    if r_idx + 1 < len(table.rows):\n",
    "                        nxt = table.rows[r_idx+1].cells[c_idx].text.strip()\n",
    "                        if nxt:\n",
    "                            return _ensure_filename_start_and_year(nxt, filename)\n",
    "                        if c_idx + 1 < len(table.rows[r_idx+1].cells):\n",
    "                            nxt2 = table.rows[r_idx+1].cells[c_idx+1].text.strip()\n",
    "                            if nxt2:\n",
    "                                return _ensure_filename_start_and_year(nxt2, filename)\n",
    "\n",
    "    for _, text in blocks:\n",
    "        low = text.lower()\n",
    "        if low.startswith(\"full report title\") or low.startswith(\"full title\"):\n",
    "            inline = _inline_title(text)\n",
    "            if inline:\n",
    "                return _ensure_filename_start_and_year(inline, filename)\n",
    "\n",
    "    skip_words = (\"strategically\", \"introduction\", \"context\")\n",
    "    for _, t in blocks:\n",
    "        tt = _norm(t)\n",
    "        low = tt.lower()\n",
    "        if any(sw in low for sw in skip_words):\n",
    "            continue\n",
    "        if low.startswith(\"the global\"):\n",
    "            continue\n",
    "        if \"table of contents\" in low or \"toc\" in low:\n",
    "            continue\n",
    "        if \"list of tables\" in low or \"list of figures\" in low:\n",
    "            continue\n",
    "        if _year_range_present(tt) and any(word in low for word in filename_low.split()):\n",
    "            return _ensure_filename_start_and_year(tt, filename)\n",
    "\n",
    "    return \"Title Not Available\"\n",
    "\n",
    "# ------------------- Extract Description -------------------\n",
    "def extract_description(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    html_output = []\n",
    "    capture, inside_list = False, False  \n",
    "\n",
    "    def run_to_html(run):\n",
    "        text = run.text.strip()\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        if run.bold and run.italic:\n",
    "            return f\"<b><i>{text}</i></b>\"\n",
    "        elif run.bold:\n",
    "            return f\"<b>{text}</b>\"\n",
    "        elif run.italic:\n",
    "            return f\"<i>{text}</i>\"\n",
    "        return text\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        low = text.lower()\n",
    "\n",
    "        if not capture and (\n",
    "            \"introduction and strategic context\" in low\n",
    "            or text.startswith(\"the global\")\n",
    "            or \"market will witness\" in low\n",
    "        ):\n",
    "            capture = True\n",
    "            html_output.append(\"<h2>Introduction and Strategic Context</h2>\")\n",
    "\n",
    "        if capture and \"report summary, faqs, and seo schema\" in low:\n",
    "            break  \n",
    "\n",
    "        if capture:\n",
    "            content = \"\".join(run_to_html(run) for run in para.runs if run.text.strip())\n",
    "            if para.style.name.startswith(\"Heading\"):\n",
    "                level = para.style.name.replace(\"Heading\", \"\").strip()\n",
    "                level = int(level) if level.isdigit() else 2\n",
    "                html_output.append(f\"<h{level}>{content}</h{level}>\")\n",
    "                continue\n",
    "\n",
    "            if \"list\" in para.style.name.lower():\n",
    "                if not inside_list:\n",
    "                    html_output.append(\"<ul>\")\n",
    "                    inside_list = True\n",
    "                html_output.append(f\"<li>{content}</li>\")\n",
    "                continue\n",
    "            else:\n",
    "                if inside_list:\n",
    "                    html_output.append(\"</ul>\")\n",
    "                    inside_list = False\n",
    "\n",
    "            html_output.append(f\"<p>{content}</p>\")\n",
    "\n",
    "    if inside_list:\n",
    "        html_output.append(\"</ul>\")\n",
    "    return _remove_emojis(\"\\n\".join(html_output))\n",
    "\n",
    "# ------------------- Coverage Table -------------------\n",
    "def extract_report_coverage_table_with_style(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    for table in doc.tables:\n",
    "        first_row_text = \" \".join([c.text.strip().lower() for c in table.rows[0].cells])\n",
    "        if \"report attribute\" in first_row_text or \"report coverage table\" in first_row_text:\n",
    "            html = []\n",
    "            html.append('<h2><strong>7.1. Report Coverage Table</strong></h2>')\n",
    "            html.append('<table cellspacing=\"0\" style=\"border-collapse:collapse; width:100%\"><tbody>')\n",
    "            for r_idx, row in enumerate(table.rows):\n",
    "                html.append(\"<tr>\")\n",
    "                for c_idx, cell in enumerate(row.cells):\n",
    "                    text = cell.text.strip()\n",
    "                    bg = \"#deeaf6\" if r_idx % 2 == 1 else \"#ffffff\"\n",
    "                    if r_idx == 0:\n",
    "                        bg = \"#5b9bd5\"\n",
    "                    td_style = (\n",
    "                        f\"background-color:{bg}; border:1px solid #9cc2e5; vertical-align:top; padding:4px; width:263px\"\n",
    "                        if c_idx == 0 else\n",
    "                        f\"background-color:{bg}; border:1px solid #9cc2e5; vertical-align:top; padding:4px; width:303px\"\n",
    "                    )\n",
    "                    html.append(\n",
    "                        f'<td style=\"{td_style}\"><p><strong>{text}</strong></p></td>'\n",
    "                        if c_idx == 0 or r_idx == 0 else f'<td style=\"{td_style}\"><p>{text}</p></td>'\n",
    "                    )\n",
    "                html.append(\"</tr>\")\n",
    "            html.append(\"</tbody></table>\")\n",
    "            return \"\\n\".join(html)\n",
    "    return \"\"\n",
    "\n",
    "# ------------------- Merger -------------------\n",
    "def merge_description_and_coverage(docx_path):\n",
    "    try:\n",
    "        desc_html = extract_description(docx_path) or \"\"\n",
    "        coverage_html = extract_report_coverage_table_with_style(docx_path) or \"\"\n",
    "        merged_html = desc_html + \"\\n\\n\" + coverage_html if (desc_html or coverage_html) else \"\"\n",
    "        return merged_html\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "# ------------------- Run Extraction -------------------\n",
    "folder_path = r\"C:\\Users\\Vishnu\\Desktop\\oldcontent\\23 june\\23 june\"\n",
    "output_path = r\"C:\\Users\\Vishnu\\Documents\\extracted_docs\\Extraction_New_Title_Old.xlsx\"\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if not file.endswith(\".docx\") or file.startswith(\"~$\"):\n",
    "        continue\n",
    "\n",
    "    doc_path = os.path.join(folder_path, file)\n",
    "    print(f\"Processing: {file}\")\n",
    "\n",
    "    title = extract_title(doc_path)\n",
    "    description_html = extract_description(doc_path)\n",
    "    report = extract_report_coverage_table_with_style(doc_path)\n",
    "    merge = merge_description_and_coverage(doc_path)\n",
    "\n",
    "    # Split merged description into Excel chunks\n",
    "    chunks = split_into_excel_cells(merge)\n",
    "\n",
    "    row_data = {\n",
    "        \"File\": file,\n",
    "        \"Title\": title,\n",
    "        \"Description\": description_html,\n",
    "        \"Report\": report,\n",
    "    }\n",
    "\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        row_data[f\"Discription_Part{i}\"] = chunk\n",
    "\n",
    "    all_data.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Done! Extracted data saved in {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
